#!/usr/bin/env python3
"""
Content Analyzer å•å…ƒæµ‹è¯•
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from content_analyzer import ContentAnalyzer
from llm_controllers import LLMController


class MockLLMController:
    """æ¨¡æ‹ŸLLMæ§åˆ¶å™¨ï¼Œç”¨äºæµ‹è¯•"""

    def get_completion(self, prompt, response_format=None, temperature=0.7):
        # è¿”å›æ¨¡æ‹Ÿçš„JSONå“åº”
        mock_response = '''{
            "keywords": ["æ—¶ä»£å¹¿åœº", "ç›’é©¬", "æ°¸è¾‰", "è¶…å¸‚"],
            "context": "Shopping location information about Times Square area",
            "tags": ["location", "shopping", "commerce"]
        }'''
        return mock_response


def test_fallback_analysis():
    """æµ‹è¯•é™çº§åˆ†æåŠŸèƒ½"""
    print("Testing fallback content analysis...")

    analyzer = ContentAnalyzer()  # ä¸æä¾›LLMæ§åˆ¶å™¨ï¼Œä½¿ç”¨é™çº§æ¨¡å¼

    # æµ‹è¯•ä¸­æ–‡å†…å®¹åˆ†æ
    content = "æ—¶ä»£å¹¿åœºå†…æœ‰ç›’é©¬å’Œæ°¸è¾‰ä¸¤å®¶è¶…å¸‚"
    result = analyzer.analyze_content(content)

    assert "keywords" in result
    assert "context" in result
    assert "tags" in result
    assert isinstance(result["keywords"], list)
    assert isinstance(result["context"], str)
    assert isinstance(result["tags"], list)

    # æ£€æŸ¥æ˜¯å¦æå–äº†ç›¸å…³å…³é”®è¯
    keywords_str = " ".join(result["keywords"])
    assert any(word in keywords_str for word in ["æ—¶ä»£å¹¿åœº", "ç›’é©¬", "æ°¸è¾‰", "è¶…å¸‚"]), f"Keywords not extracted properly: {result['keywords']}"

    print("âœ“ Fallback analysis tests passed")


def test_mock_llm_analysis():
    """æµ‹è¯•æ¨¡æ‹ŸLLMåˆ†æåŠŸèƒ½"""
    print("Testing mock LLM content analysis...")

    # ä½¿ç”¨æ¨¡æ‹ŸLLMæ§åˆ¶å™¨
    mock_controller = MockLLMController()
    analyzer = ContentAnalyzer(llm_controller=mock_controller)

    content = "æ—¶ä»£å¹¿åœºå†…æœ‰ç›’é©¬å’Œæ°¸è¾‰ä¸¤å®¶è¶…å¸‚"
    result = analyzer.analyze_content(content)

    assert "keywords" in result
    assert "context" in result
    assert "tags" in result

    # æ£€æŸ¥æ¨¡æ‹Ÿå“åº”æ˜¯å¦æ­£ç¡®è§£æ
    assert "æ—¶ä»£å¹¿åœº" in result["keywords"]
    assert "ç›’é©¬" in result["keywords"]
    assert "shopping" in result["context"].lower()
    assert "location" in result["tags"]

    print("âœ“ Mock LLM analysis tests passed")


def test_empty_content():
    """æµ‹è¯•ç©ºå†…å®¹åˆ†æ"""
    print("Testing empty content analysis...")

    analyzer = ContentAnalyzer()

    # æµ‹è¯•ç©ºå†…å®¹
    result = analyzer.analyze_content("")
    assert result["keywords"] == ["general"]
    assert result["context"] == "General content"
    assert result["tags"] == ["general"]

    # æµ‹è¯•Noneå†…å®¹
    result = analyzer.analyze_content(None)
    assert result["keywords"] == ["general"]

    print("âœ“ Empty content analysis tests passed")


def test_context_inference():
    """æµ‹è¯•ä¸Šä¸‹æ–‡æ¨æ–­åŠŸèƒ½"""
    print("Testing context inference...")

    analyzer = ContentAnalyzer()

    # æµ‹è¯•è´­ç‰©ç›¸å…³å†…å®¹
    shopping_content = "æ—¶ä»£å¹¿åœº ç›’é©¬ æ°¸è¾‰ è¶…å¸‚ è´­ç‰©"
    result = analyzer.analyze_content(shopping_content)
    assert "shopping" in result["context"].lower()

    # æµ‹è¯•æŠ€æœ¯ç›¸å…³å†…å®¹
    tech_content = "Python ç¼–ç¨‹ å¼€å‘ ä»£ç  æŠ€æœ¯"
    result = analyzer.analyze_content(tech_content)
    assert any(word in result["tags"] for word in ["technology", "programming"])

    print("âœ“ Context inference tests passed")


def test_response_parsing():
    """æµ‹è¯•å“åº”è§£æåŠŸèƒ½"""
    print("Testing response parsing...")

    analyzer = ContentAnalyzer()

    # æµ‹è¯•æ­£å¸¸JSONå“åº”
    normal_response = '{"keywords": ["test"], "context": "test context", "tags": ["test"]}'
    result = analyzer._parse_llm_response(normal_response)
    assert result["keywords"] == ["test"]
    assert result["context"] == "test context"
    assert result["tags"] == ["test"]

    # æµ‹è¯•å¸¦é¢å¤–æ–‡æœ¬çš„JSONå“åº”
    extra_text_response = 'Here is the analysis: {"keywords": ["test"], "context": "test context", "tags": ["test"]} And some more text.'
    result = analyzer._parse_llm_response(extra_text_response)
    assert result["keywords"] == ["test"]

    # æµ‹è¯•æ— æ•ˆJSONå“åº”ï¼ˆåº”è¯¥é™çº§ï¼‰
    invalid_response = "This is not JSON at all"
    result = analyzer._parse_llm_response(invalid_response)
    # åº”è¯¥è¿”å›é™çº§ç»“æœ
    assert isinstance(result["keywords"], list)
    assert isinstance(result["context"], str)

    print("âœ“ Response parsing tests passed")


def test_analyzer_update():
    """æµ‹è¯•åˆ†æå™¨æ›´æ–°åŠŸèƒ½"""
    print("Testing analyzer update...")

    analyzer = ContentAnalyzer()

    # åˆå§‹çŠ¶æ€ï¼šæ— LLMæ§åˆ¶å™¨
    assert not analyzer.llm_available

    # æ›´æ–°ä¸ºæœ‰LLMæ§åˆ¶å™¨çš„çŠ¶æ€
    mock_controller = MockLLMController()
    analyzer.update_llm_controller(mock_controller)
    assert analyzer.llm_available
    assert analyzer.llm_controller is mock_controller

    # å†æ¬¡æ›´æ–°ä¸ºæ— LLMæ§åˆ¶å™¨
    analyzer.update_llm_controller(None)
    assert not analyzer.llm_available

    print("âœ“ Analyzer update tests passed")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("Running Content Analyzer unit tests...\n")

    try:
        test_fallback_analysis()
        test_mock_llm_analysis()
        test_empty_content()
        test_context_inference()
        test_response_parsing()
        test_analyzer_update()

        print("\nğŸ‰ All Content Analyzer tests passed!")
        return True

    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
