#!/usr/bin/env python3
"""
ç®€åŒ–çš„ AgenticMemory åŠŸèƒ½æ¼”ç¤º

ç›´æ¥å±•ç¤ºè®°å¿†åˆ†æå’Œæ£€ç´¢åŠŸèƒ½ï¼Œä¸ä¾èµ–å¤æ‚çš„å¯¼å…¥
"""

import os
import json

def load_config():
    """åŠ è½½é…ç½®"""
    config_file = "agentflow/agentflow/models/memory/config.env"
    if os.path.exists(config_file):
        with open(config_file, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    if '=' in line:
                        key, value = line.split('=', 1)
                        os.environ[key.strip()] = value.strip()
        return True
    return False

def demonstrate_memory_analysis():
    """æ¼”ç¤ºè®°å¿†åˆ†æåŠŸèƒ½"""
    print("ğŸ§  è®°å¿†åˆ†æåŠŸèƒ½æ¼”ç¤º")
    print("=" * 40)

    try:
        import litellm
        from litellm import completion

        # æµ‹è¯•è®°å¿†å†…å®¹
        test_memories = [
            "æ—¶ä»£å¹¿åœºä¸­æœ‰ç›’é©¬ã€æ°¸è¾‰ç­‰è¶…å¸‚ï¼Œæä¾›æ–°é²œè”¬æœå’Œæ—¥ç”¨å“",
            "æ—¶ä»£å¹¿åœºé™„è¿‘æœ‰æ˜Ÿå·´å…‹å’–å•¡åº—ï¼Œç¯å¢ƒèˆ’é€‚ï¼Œé€‚åˆå·¥ä½œå’Œä¼‘æ¯",
            "æ—¶ä»£å¹¿åœºå‘¨è¾¹äº¤é€šä¾¿åˆ©ï¼Œæœ‰åœ°é“ç«™å’Œå¤šä¸ªå…¬äº¤ç«™ç‚¹"
        ]

        print("ğŸ“ æ­£åœ¨åˆ†æè®°å¿†å†…å®¹...\n")

        for i, content in enumerate(test_memories, 1):
            print(f"è®°å¿† {i}: {content}")

            # æ„å»ºåˆ†ææç¤º
            analysis_prompt = f"""Generate a structured analysis of the following content by:
1. Identifying the most salient keywords (focus on nouns, verbs, and key concepts)
2. Extracting core themes and contextual elements
3. Creating relevant categorical tags

Format the response as a JSON object:
{{
    "keywords": ["keyword1", "keyword2", ...],
    "context": "One sentence summarizing the content",
    "tags": ["tag1", "tag2", ...]
}}

Content for analysis:
{content}"""

            # è°ƒç”¨ LLM åˆ†æ
            response = completion(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": analysis_prompt}],
                api_key=os.environ.get('LITELLM_API_KEY'),
                api_base=os.environ.get('LITELLM_API_BASE'),
                temperature=0.3,
                max_tokens=200
            )

            # è§£æç»“æœ
            result_text = response.choices[0].message.content

            # æ¸…ç† JSON
            result_text = result_text.strip()
            if result_text.startswith('```json'):
                result_text = result_text[7:]
            if result_text.endswith('```'):
                result_text = result_text[:-3]
            result_text = result_text.strip()

            try:
                analysis = json.loads(result_text)
                print("   ğŸ”‘ å…³é”®è¯:", analysis.get('keywords', []))
                print("   ğŸ“ ä¸Šä¸‹æ–‡:", analysis.get('context', ''))
                print("   ğŸ·ï¸ æ ‡ç­¾:", analysis.get('tags', []))
            except json.JSONDecodeError:
                print("   âš ï¸ åˆ†æç»“æœè§£æå¤±è´¥")
                print(f"   åŸå§‹ç»“æœ: {result_text[:100]}...")

            print()

    except Exception as e:
        print(f"âŒ è®°å¿†åˆ†ææ¼”ç¤ºå¤±è´¥: {e}")

def demonstrate_semantic_search():
    """æ¼”ç¤ºè¯­ä¹‰æœç´¢åŠŸèƒ½"""
    print("ğŸ” è¯­ä¹‰æœç´¢åŠŸèƒ½æ¼”ç¤º")
    print("=" * 40)

    try:
        from sentence_transformers import SentenceTransformer
        import numpy as np
        from sklearn.metrics.pairwise import cosine_similarity

        # åˆå§‹åŒ–æ¨¡å‹
        print("ğŸ¤– åŠ è½½è¯­ä¹‰æ¨¡å‹...")
        model = SentenceTransformer('all-MiniLM-L6-v2')

        # è®°å¿†åº“
        memories = [
            "æ—¶ä»£å¹¿åœºä¸­æœ‰ç›’é©¬ã€æ°¸è¾‰ç­‰è¶…å¸‚ï¼Œæä¾›æ–°é²œè”¬æœå’Œæ—¥ç”¨å“",
            "æ—¶ä»£å¹¿åœºé™„è¿‘æœ‰æ˜Ÿå·´å…‹å’–å•¡åº—ï¼Œç¯å¢ƒèˆ’é€‚ï¼Œé€‚åˆå·¥ä½œå’Œä¼‘æ¯",
            "æ—¶ä»£å¹¿åœºå‘¨è¾¹äº¤é€šä¾¿åˆ©ï¼Œæœ‰åœ°é“ç«™å’Œå¤šä¸ªå…¬äº¤ç«™ç‚¹",
            "æ—¶ä»£å¹¿åœºæ˜¯åŸå¸‚ä¸­å¿ƒå•†ä¸šåŒºï¼Œæœ‰å¾ˆå¤šé¤å…å’Œå¨±ä¹åœºæ‰€",
            "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯",
            "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œç‰¹å¾æå–"
        ]

        print(f"ğŸ“š è®°å¿†åº“åŒ…å« {len(memories)} æ¡è®°å¿†\n")

        # ç”ŸæˆåµŒå…¥
        print("ğŸ”¢ è®¡ç®—è¯­ä¹‰åµŒå…¥...")
        embeddings = model.encode(memories)

        # æµ‹è¯•æŸ¥è¯¢
        queries = [
            "æ—¶ä»£å¹¿åœºå‘¨è¾¹æœ‰ä»€ä¹ˆè¶…å¸‚",
            "æ—¶ä»£å¹¿åœºé™„è¿‘æœ‰å’–å•¡åº—å—",
            "æ—¶ä»£å¹¿åœºäº¤é€šæ€ä¹ˆæ ·",
            "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "
        ]

        for query in queries:
            print(f"â“ æŸ¥è¯¢: {query}")

            # è®¡ç®—æŸ¥è¯¢åµŒå…¥
            query_emb = model.encode([query])

            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = cosine_similarity(query_emb, embeddings)[0]

            # è·å–æœ€ç›¸å…³çš„ç»“æœ
            top_indices = np.argsort(similarities)[-3:][::-1]  # Top 3
            top_scores = similarities[top_indices]

            print("ğŸ¯ æœ€ç›¸å…³ç»“æœ:")
            for i, (idx, score) in enumerate(zip(top_indices, top_scores), 1):
                if score > 0.1:  # åªæ˜¾ç¤ºç›¸å…³åº¦è¶³å¤Ÿé«˜çš„ç»“æœ
                    print(".3f")
                    print(f"   è®°å¿†: {memories[idx]}")

            print()

    except Exception as e:
        print(f"âŒ è¯­ä¹‰æœç´¢æ¼”ç¤ºå¤±è´¥: {e}")
        print("è¯·ç¡®ä¿å®‰è£…äº† sentence-transformers å’Œ scikit-learn")

def demonstrate_cli_usage():
    """æ¼”ç¤º CLI ä½¿ç”¨æ–¹æ³•"""
    print("ğŸ’» å‘½ä»¤è¡Œå·¥å…·ä½¿ç”¨æ¼”ç¤º")
    print("=" * 40)

    print("æ‚¨å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤æ¥ä½¿ç”¨äº¤äº’å¼è®°å¿†å·¥å…·:")
    print()
    print("1. å¯åŠ¨äº¤äº’å¼å·¥å…·:")
    print("   cd /root/autodl-tmp/FreeAskAgent")
    print("   python memory_cli.py")
    print()
    print("2. åœ¨å·¥å…·ä¸­å¯ä»¥æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
    print()
    print("   æ·»åŠ è®°å¿†:")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: åœ¨æ—¶ä»£å¹¿åœºä¸­æœ‰ç›’é©¬ã€æ°¸è¾‰ç­‰è¶…å¸‚")
    print("   æˆ–")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: add åœ¨æ—¶ä»£å¹¿åœºä¸­æœ‰ç›’é©¬ã€æ°¸è¾‰ç­‰è¶…å¸‚")
    print()
    print("   æŸ¥è¯¢è®°å¿†:")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: query æ—¶ä»£å¹¿åœºå‘¨è¾¹æœ‰ä»€ä¹ˆè¶…å¸‚")
    print()
    print("   åˆ—å‡ºæ‰€æœ‰è®°å¿†:")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: list")
    print()
    print("   æŸ¥çœ‹ç»Ÿè®¡:")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: stats")
    print()
    print("   è·å–å¸®åŠ©:")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: help")
    print()
    print("   é€€å‡ºå·¥å…·:")
    print("   ğŸ“ è¯·è¾“å…¥å‘½ä»¤: quit")

def show_integration_example():
    """æ˜¾ç¤ºé›†æˆç¤ºä¾‹"""
    print("ğŸ”— ä»£ç é›†æˆç¤ºä¾‹")
    print("=" * 40)

    print("""
# åœ¨æ‚¨çš„ Python ä»£ç ä¸­ä½¿ç”¨ AgenticMemory

import os
# è®¾ç½® API å¯†é’¥
os.environ['LITELLM_API_KEY'] = 'sk-mQRVq6Mved8vHoJklaJQnLabN0sT9KEnc2Vw45bniUAvBYPL'
os.environ['LITELLM_API_BASE'] = 'https://yinli.one/v1'

# æ³¨æ„ï¼šç”±äºå¯¼å…¥é—®é¢˜ï¼Œå»ºè®®ç›´æ¥ä½¿ç”¨ç»„ä»¶
from sentence_transformers import SentenceTransformer
import litellm
from litellm import completion

# 1. åˆ›å»ºè¯­ä¹‰æœç´¢åŠŸèƒ½
model = SentenceTransformer('all-MiniLM-L6-v2')

# 2. ç»´æŠ¤è®°å¿†åº“
memories = []

def add_memory(content):
    \"\"\"æ·»åŠ è®°å¿†\"\"\"
    # ä½¿ç”¨ LLM åˆ†æè®°å¿†
    analysis_prompt = f'''åˆ†æè¿™æ®µå†…å®¹ï¼Œæå–å…³é”®è¯å’Œæ ‡ç­¾:
{content}

è¿”å› JSON æ ¼å¼: {{"keywords": [], "tags": []}}'''

    response = completion(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": analysis_prompt}],
        api_key=os.environ['LITELLM_API_KEY'],
        api_base=os.environ['LITELLM_API_BASE']
    )

    # å­˜å‚¨è®°å¿†
    memories.append({
        'content': content,
        'embedding': model.encode([content])[0],
        'analysis': response.choices[0].message.content
    })

def search_memories(query, top_k=3):
    \"\"\"æœç´¢ç›¸å…³è®°å¿†\"\"\"
    if not memories:
        return []

    query_emb = model.encode([query])[0]
    similarities = []

    for mem in memories:
        sim = np.dot(query_emb, mem['embedding']) / (
            np.linalg.norm(query_emb) * np.linalg.norm(mem['embedding'])
        )
        similarities.append((sim, mem))

    # æ’åºå¹¶è¿”å› top_k
    similarities.sort(reverse=True, key=lambda x: x[0])
    return similarities[:top_k]

# ä½¿ç”¨ç¤ºä¾‹
add_memory("æ—¶ä»£å¹¿åœºä¸­æœ‰ç›’é©¬ã€æ°¸è¾‰ç­‰è¶…å¸‚")
results = search_memories("æ—¶ä»£å¹¿åœºå‘¨è¾¹æœ‰ä»€ä¹ˆè¶…å¸‚")

for score, mem in results:
    print(f"ç›¸ä¼¼åº¦: {score:.3f}")
    print(f"å†…å®¹: {mem['content']}")
    print(f"åˆ†æ: {mem['analysis']}")
    """)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ AgenticMemory åŠŸèƒ½æ¼”ç¤º")
    print("è®© AI è®°ä½ä¸€åˆ‡ï¼Œéšæ—¶æŸ¥è¯¢ï¼")
    print("=" * 50)

    # åŠ è½½é…ç½®
    if not load_config():
        print("âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")

    # æ£€æŸ¥ API Key
    if not os.getenv('LITELLM_API_KEY'):
        print("âŒ æœªè®¾ç½® API Keyï¼Œè¯·æ£€æŸ¥é…ç½®")
        return

    print("âœ… é…ç½®æ£€æŸ¥é€šè¿‡\n")

    # è¿è¡Œæ¼”ç¤º
    demonstrate_memory_analysis()
    demonstrate_semantic_search()
    demonstrate_cli_usage()
    show_integration_example()

    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("ğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨ AgenticMemory åŠŸèƒ½äº†ï¼")
    print("ğŸš€ è¿è¡Œ 'python memory_cli.py' å¼€å§‹äº¤äº’å¼ä½“éªŒ")

if __name__ == "__main__":
    main()
